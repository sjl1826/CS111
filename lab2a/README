lab2_add.c: This program implements an add function that uses a shared variable for testing.
SortedList.h: This is a header file for the linked list functions that are implemented in SortedList.c.
SortedList.c: This file contains the implementations of linked list operations such as insert, delete, lookup, and length as well.
lab2_list.c: This file is a program that uses linked lists to build output statistics for threads with linked lists.
Makefile: This file is used to build the programs, output, graphs, and tarball. It is also used to test.
lab2_add.csv: This file contains all of my results from Part 1 tests in lab2_add.c.
lab2_list.csv: This file contains all of my results from Part 2 tests in lab2_list.c.
The graph files contain all the graphs of the results that were created by running gnuplot on the csv files.


QUESTION 2.1.1 - causing conflicts:
	 Why does it take many iterations before errors are seen?
	     It takes many iterations before errors are seen because with a small number of iterations, threads can finish before the other threads are created. When there are many more iterations, each thread takes up more time, allowing multiple threads to update counter at the same time.
	 Why does a significantly smaller number of iterations so seldom fail?
	     With a smaller number of iterations, threads can finish quicker before any conflicts between threads could happen, therefore minimizing the possibility of failing.

QUESTION 2.1.2 - cost of yielding:
	 Why are the --yield runs so much slower?
	     Enabling yielding will allow "sched_yield()" calls to be made which will involve context switches, waiting, ultimately adding more time and slowing down the run.
	 Where is the additional time going?
	       The additional time is going to context switches.
	 Is it possible to get valid per-operation timings if we are using the --yield option? If so, explain how. If not, explain why not.
	 It is not possible to get valid per-operation timings if we are using the --yield option. To get per-operation timings, we'd be assuming that multiple yield functions are not running at the same time. This would make it difficult.

QUESTION 2.1.3 - measurement errors:
	 Why does the average cost per operation drop with increasing iterations?
	     The average cost per operation drops because most of the time is now spent on iterations rather than context switches, which are more costly. Iterations are faster and not as expensive, therefore lowering the average cost per operation.
	 If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the "correct" cost is)?
	    If the cost per iteration is a function of the number of iterations, c = f(i). If we were to graph this function, the iterations that cause c to be constant (a horizontal line) would be the correct cost.

QUESTION 2.1.4 - costs of serialization:
	 Why do all of the options perform similarly for low numbers of threads?
	     All of the options perform similarly for low numbers of threads because since there is a low number of threads, the issues of unprotection aren't as relevant, therefore showing similar performance in a low number of threads execution.
	 Why do the three protected operations slow down as the number of threads rises?
	     The three protected operations slow down as the number of threads rises because the operations must need a lock, which is costly in time therefore slowing down the operations.

QUESTION 2.2.1 - Scalability of Mutex
	 Compare the variation in time per mutex-protected operation vs the number of threads in Part-1 (adds) and Part-2 (sorted lists).
	 The Part-1 graph of time per mutex-protected operation is linear at first and then it turns into a horizontal line. The Part-2 graph of time per mutex-protected operation is linear at first and then has a bit of mountain-like variation at the end. The Part-1 graph is steeper in time per mutex-protected operation whereas the Part-2 graph is not very steep.	 
	 Comment on the general shapes of the curves, and explain why they have this shape.
	 The shapes of the curves seem to go up with lower threads and then become a more stable line, slightly angled down at a bigger number of threads. More threads will be waiting for mutex, therefore lowering the cost per operations with more time.
	 Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
	 The cost of mutex will go up with an increase in threads, however will lower with even more threads because it will cause threads to sleep and lower the rates. The differences show the time cost of linked lists versus the number of threads.
	 
QUESTION 2.2.2 - scalability of spin locks
	 Compare the variation in time per protected operation vs the number of threads for list operations protected by Mutex vs Spin locks. Comment on the general shapes of the curves, and explain why they have this shape.
	 Mutex and spinlock had really similar graph shapes. Spin lock was slightly higher in terms of time. The shapes start out flat, rise, decrease, and then rise again. The curves are similar to mountains that are becoming steeper. They have this shape because it shows that for the increeasing number of threads, the time per protected operation increases.	 
	 Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
	 The rates of increase are very similar as well as the shapes of the curves. Both protections have to wait for the operations and therefore act the same. The rate of increase stay relatively stable as the graphs are fairly linear. It shows that there is a slightly consistent rate of increase, showing that the increase in the number of threads will result in an increase in time per protected operation.